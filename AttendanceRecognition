import csv
from datetime import datetime

import cv2
import face_recognition
import numpy as np
import os
import glob
import time

t_end = time.time() + 60

video_capture = cv2.VideoCapture(0)

#Image Uploading
iyyappan_image = face_recognition.load_image_file(r"C:\Users\selva\PycharmProjects\Smart_Classroom\ImagesBasic\iyyapu.jpg")
iyyappan_encoding = face_recognition.face_encodings(iyyappan_image)[0]
nandha_image = face_recognition.load_image_file(r"C:\Users\selva\PycharmProjects\Smart_Classroom\ImagesBasic\nandha.jpg")
nandha_encoding = face_recognition.face_encodings(nandha_image)[0]
divyamsh_image = face_recognition.load_image_file(r"C:\Users\selva\PycharmProjects\Smart_Classroom\ImagesBasic\divyamsh.jpg")
divyamsh_encoding = face_recognition.face_encodings(divyamsh_image)[0]
pranav_image = face_recognition.load_image_file(r"C:\Users\selva\PycharmProjects\Smart_Classroom\ImagesBasic\pranav.jpg")
pranav_encoding = face_recognition.face_encodings(pranav_image)[0]
joan_image = face_recognition.load_image_file(r"C:\Users\selva\PycharmProjects\Smart_Classroom\ImagesBasic\joan.jpg")
joan_encoding = face_recognition.face_encodings(joan_image)[0]
#arun_image = face_recognition.load_image_file(r"C:\Users\selva\PycharmProjects\Smart_Classroom\ImagesBasic\dhoni.jpg")
#arun_encoding = face_recognition.face_encodings(arun_image)[0]

known_face_encoding = [
iyyappan_encoding,
nandha_encoding,
divyamsh_encoding,
pranav_encoding,
joan_encoding
#dhoni_encoding
]

known_faces_names = [
"iyyappan",
"nandha",
"divyamsh",
"pranav",
"joan"
#"dhoni"
]
students = known_faces_names.copy()
face_locations = []
face_encodings = []
face_names = []
s=True

now =datetime.now()
current_date = now.strftime("%Y-%m-%d")

f = open(current_date + '.csv', 'a', newline='')
lnwriter = csv.writer(f)

while time.time() < t_end:
    _,frame = video_capture.read()
    small_frame = cv2.resize(frame,(0,0),fx = 0.25, fy = 0.25)
    rgb_small_frame = small_frame[:,:,::-1]

    if s:
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame,face_locations)
        face_names = []
        for face_encoding in face_encodings:
            matches = face_recognition.compare_faces(known_face_encoding,face_encoding)
            name = ''
            face_distance = face_recognition.face_distance(known_face_encoding, face_encoding)
            best_match_index = np.argmin(face_distance)

            if matches[best_match_index]:
                name = known_faces_names[best_match_index]

            face_names.append(name)
            if name in known_faces_names:
                if name in students:
                    students.remove(name)
                    print(name,"present")
                    current_time = now.strftime("%H-%M-%S")
                    lnwriter.writerow([name, current_time])

    cv2.imshow("attendace_system", frame)
    if cv2.waitKey(1) and 0xFF == ord('q'):
        break


video_capture.release()
cv2.destroy_all_windows()
f.close()



